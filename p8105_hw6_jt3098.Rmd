---
title: "p8105_hw6_jt3098"
author: "Jieqi Tu (jt3098)"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(questionr)
library(purrr)
library(modelr)
```

## Problem 1

#### Data importing
```{r data importing for problem 1, message=FALSE}
# import data for problem 1
homicide_data = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

#### Data cleaning and manipulation
```{r creating and manipulating variables, message=FALSE}
# Make a "city_state" variable
homicide_data = 
  homicide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  select(-city, -state)

# Make a binary variable to show whether this case is solved
# "0" means the case is unsolved yet, and "1" means the case is already solved
homicide_data = 
  homicide_data %>%
  mutate(case_status = ifelse(disposition == "Closed by arrest", 1, 0))

# Make sure that the "victim_age" is numeric
homicide_data = 
  homicide_data %>%
  mutate(victim_age = as.numeric(victim_age))


# Omit several cities that do not have the correct information
homicide_data = 
  homicide_data %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))

# Modify "victim_race" variable
homicide_data = 
  homicide_data %>%
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white"),
         victim_race = fct_relevel(victim_race, "white", "non-white")) 

```

#### Regression Analysis for Baltimore city
```{r Baltimore regression}
# Create a new dataframe that only contains data about Baltimore city
homicide_Baltimore =
  homicide_data %>%
  filter(city_state == "Baltimore, MD")

# Fit a glm regression for Baltimore
Baltimore_glm = glm(case_status ~ victim_age + victim_race + victim_sex, data = homicide_Baltimore, family = binomial)

# See the result of the glm regression
broom::tidy(Baltimore_glm) %>% knitr::kable()
```

```{r odds ratio, message=FALSE}
# Calculate the estimation and confidence interval of odds ratio
status_sex_glm = glm(case_status ~ victim_sex + victim_race + victim_age, data = homicide_Baltimore, family = binomial)
ci_oddsratio = odds.ratio(status_sex_glm, level = 0.95)
ci_oddsratio =
  ci_oddsratio %>%
  as.data.frame() %>%
  select(-p) %>%
  round(digits = 3)

ci_oddsratio %>% knitr::kable()
```

Comments: From the result, we could know that the OR estimate is 0.441 with the 95% CI: [0.312, 0.620], keeping all other variables fixed.

```{r odds ratio for each city}
# Make list columns to make glm results for each city
homicide_city_glm =
  homicide_data %>% 
  # first creating a listcolumn organized by city_state
  group_by(city_state) %>% 
  nest() %>% 
  # running glm on every city
  mutate(regression = map(data, ~glm(case_status ~ victim_sex + victim_race + victim_age, 
                                      family = binomial, data = .x)), 
         regression = map(regression, broom::tidy)) %>% 
  select(-data) 
```

```{r unnest the result of glm}
# Unnest the glm result and select only the race term
homicide_city_glm =
  homicide_city_glm %>%
  unnest() %>%
  filter(term == "victim_racenon-white")

# Calculate the confidence interval for each city
homicide_city_glm = 
  homicide_city_glm %>%
  mutate(OR = exp(estimate),
         OR_lower = exp(estimate - 1.96 * std.error), 
         OR_upper = exp(estimate + 1.96 * std.error), 
         city_state = fct_reorder(city_state, estimate)) %>% 
  select(city_state, OR, OR_lower, OR_upper)
```

```{r making a plot to show the ci for each city}
homicide_city_glm %>%
  ggplot(aes(x = city_state, y = OR)) + geom_point() +
  geom_errorbar(aes(ymin = OR_lower, ymax = OR_upper)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, size = 8)) +
  labs(
    title = "Odds Ratio and 95% Confidence Interval for Each City",
    x = "City, State",
    y = "Odds Ratio and 95% Confidence Interval"
  )
```

Comments: From the graph, we could see that, Boston has the lowest odds ratio, while Tempa has the highest odds ratio. It is also noticeable that Durham has the widest confidence interval range.

### Problem 2

#### Data importing
```{r data importing for problem 2, message=FALSE}
# Import dataset for problem 2
birthweight_data = read_csv("./data/birthweight.csv")
```

```{r data cleaning and manipulation for birthweight data}
# Convert variable types from numeric to factor
birthweight_data$babysex = as.factor(birthweight_data$babysex)
birthweight_data$frace = as.factor(birthweight_data$frace)
birthweight_data$mrace = as.factor(birthweight_data$mrace)

# Check for NA values
n_NA = sapply(birthweight_data[1:20], function(x) sum(length(which(is.na(x)))))
n_NA %>% knitr::kable()
```

```{r model building for birthweight data}
# Construct a multiple linear model with all predictors for birthweight
birthweight_lm_all = lm(bwt ~ ., data = birthweight_data)
summary(birthweight_lm_all) # Check the estimates and p-values for all predictors

# Use step-wise method to build a linear model with fewer predictors
step(birthweight_lm_all, direction = "backward")
```

```{r plot for the model}

```

